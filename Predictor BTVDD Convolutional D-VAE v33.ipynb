{"cells":[{"metadata":{},"cell_type":"markdown","source":"VAE test versions. \n\nOptions (important note: for all of these that reconstruction loss is multiplied by img_dim^2)\nLoss can be \"mse\" or \"xent\"\n\nBasic VAE \n    \"vanilla\": Loss = Reconstruction_loss + KL_loss\n\nControlled capacity increase \n    \"cc\": Loss = Reconstruction_loss + gamma(KL_loss - C) (NOT WORKING YET!)\n\nBeta\n    \"beta\": Loss = Reconstruction_loss + beta|(KL_loss - C)|\n\nDecomposition\n    \"d\": Loss = Reconstruction_loss + beta(KL_loss) + alpha(Divergence)\n    \"dii\": Loss = Reconstruction_loss + beta(KL_loss) + alpha(Divergence_ii)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom scipy.stats import norm\nimport os\nimport cv2\nimport pandas as pd\n\nimport pickle\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.patches as mpatches\n\nimport tensorflow as tf\n\nimport keras\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\nfrom keras.models import Model, Sequential\nfrom keras.datasets import mnist\nfrom keras import regularizers\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.models import load_model\nfrom keras.callbacks import Callback\nfrom keras import layers\nfrom keras import metrics\n\nimport scipy\nfrom scipy.stats import norm\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# functions\ndef rgb2gray(rgba, img_dim, crop):\n    \"\"\"Returns scaled, cropped (and grayscale) image array\n    \"\"\"\n    img = rgba[crop:-crop, crop:-crop]\n    img = cv2.resize(img, dsize=(img_dim, img_dim),interpolation=cv2.INTER_CUBIC)\n    if len(img.shape) == 3:\n        if img.shape[2] == 4:\n            img = np.dot(img[...,:3], [0.2989, 0.5870, 0.1140])\n    return(img)\n\n\ndef openimg(fn):\n    \"\"\"Returns image array from filename and isValid result \n    \"\"\"\n    try:\n        with open(fn, 'rb') as handle:\n            img = pickle.load(handle, encoding='latin1')\n            isValid = True\n    except Exception as e:\n        print(e)\n        img = []\n        isValid = False\n    return(img, isValid)\n\n\ndef save_obj(obj, fname):\n    \"\"\"Pickles object to file location\n    \"\"\"\n    with open(fname + '.pkl', 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n    return()\n\n\ndef openImgFile(imgdir, indexfn, pathstr, frac, img_dim, crop, nplot, hack):\n    \"\"\"Opens and returns image files as array and index file dataframe \n    \"\"\"\n    if hack:\n        num_images = len(os.listdir(imgdir))\n        raw = np.zeros((num_images, img_dim*img_dim))\n        df = []\n        for i, fn in enumerate(os.listdir(imgdir)):\n            img = mpimg.imread(os.path.join(imgdir,fn)) \n            result = True\n            if result:\n                img = rgb2gray(img, img_dim, crop)\n                #scale between 0 and 1\n                img = (img - np.min(img)) / (np.max(img) - np.min(img))\n                fimg = img.flatten()\n                raw[i,:,] = fimg\n                if i % nplot == 0:\n                    plt.imshow(img, cmap=plt.get_cmap('gray'))\n                    plt.show()\n        return(raw, df, num_images)\n    else:     \n        with open(os.path.join(imgdir, indexfn), 'rb') as handle:\n            df = pickle.load(handle, encoding='latin1')\n\n        num_images = len(df)//frac\n\n        df['filename'] = df['filename'].str.replace(pathstr, imgdir)\n        df = df[0:num_images]\n\n        raw = np.zeros((num_images, img_dim*img_dim))\n\n        for i in range(num_images):\n            fn = df.filename.iloc[i]\n            img, result = openimg(fn)  \n            if result:\n                img = rgb2gray(img, img_dim, crop)\n                #scale between 0 and 1\n                img = (img - np.min(img)) / (np.max(img) - np.min(img))\n                fimg = img.flatten()\n                raw[i,:,] = fimg\n                if i % nplot == 0:\n                    plt.imshow(img, cmap=plt.get_cmap('gray'))\n                    plt.title(\"sample {} numBatches {}\".format(i,df.numBatches[i]))\n                    plt.show()\n        return(raw, df, num_images)\n\n\ndef makeTrainValdata(raw_x, df, preds, img_dim, split):\n    \"\"\"Returns test and validation datasets from index, predictor list and image array \n    \"\"\"\n    y = np.array(df[preds].values)\n    num_predictors =  y.shape[1]\n    X = raw_x.reshape((raw_x.shape[0], img_dim, img_dim, 1))\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=split)\n    return(num_predictors, x_train, x_test, y_train, y_test)\n    \n\ndef rsq(x, y):\n    \"\"\" Return R^2 where x and y are array-like.\n    \"\"\"\n    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x.astype(float), y)\n    return r_value**2\n\n\ndef create_predictor(d1, d2):\n    '''Creates a regressor that estimates c values from latent z variables.\n    '''\n    predictor_input = layers.Input(shape=(d1,))\n    x = layers.Dense(128, activation='relu')(predictor_input)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dense(d2, activation='linear')(x)\n    return Model(predictor_input, x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom classes\n\nclass CapacityIncrease(Callback):\n    '''Creates custom callback object for increasing capacity\n    '''    \n    def __init__(self, max_capacity, max_epochs):\n        self.max_capacity = max_capacity\n        self.current_capacity = 0\n        self.max_epochs = max_epochs\n        super(Callback).__init__()\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if epoch < self.max_epochs:\n            self.current_capacity = self.max_capacity * epoch / self.max_epochs\n        else:\n            self.current_capacity = self.max_capacity\n        print(\"Updated vae capacity param: \", self.current_capacity)\n        vae.max_capacity = self.current_capacity\n\n        \nclass vaeModel(object):\n    '''Creates vae model object\n    '''\n    def __init__(self, alpha, beta, gamma, lr, capacity, img_shape, latent_dim, filters, vae_type=\"beta\", loss = \"xent\"):\n        # Model\n        self.model = self.build_model()\n        # Print a model summary\n        self.model.summary()\n        self.optimizer = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n        self.loss_func = self.model_loss()\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.vae_type = vae_type\n        self.reg = img_shape[0]*img_shape[1]\n        #self.capacity = capacity\n        self.built = True\n        super(Layer).__init__()\n\n    def model_loss(self):\n        \"\"\"\" Wrapper function which calculates auxiliary values for the complete loss function.\n        Returns a *function* which calculates the complete loss given only the input and target output \n        \"\"\"\n        # KL loss\n        kl_loss = self.L_KL\n        # cross-entropy reconstruction loss\n        xent_loss_func = self.L_XENT\n        # mse reconstruction loss\n        mse_loss_func = self.L_MSE\n        # KL D loss\n        kl_d_loss_func = self.L_KL_D\n        # KL Dii loss\n        kl_dii_loss_func = self.L_KL_Dii\n        \n        #self.max_capacity = capacity\n        #max_capacity = self.max_capacity\n        \n        def seq2seq_loss(x, z_decoded):\n            \"\"\" Final loss calculation function to be passed to optimizer\n            \"\"\"\n            # Reconstruction loss\n            if loss_type == \"xent\":\n                r_loss = xent_loss_func(x, z_decoded)\n            else:\n                r_loss = mse_loss_func(x, z_decoded)\n            \n            # decomposition loss\n            kl_d_loss = kl_d_loss_func()\n            kl_dii_loss = kl_dii_loss_func()\n            \n            # Full loss\n            if self.vae_type == \"beta\":\n                model_loss = K.mean(r_loss + self.beta * kl_loss())\n            elif self.vae_type == \"cc\":\n                model_loss = K.mean(r_loss + self.gamma * K.abs(kl_loss() - self.capacity))\n            elif self.vae_type == \"d\":\n                model_loss = K.mean(r_loss + self.beta * kl_loss() + self.alpha * kl_d_loss)\n            elif self.vae_type == \"dii\":\n                model_loss = K.mean(r_loss + self.beta * kl_loss() + self.alpha * kl_dii_loss)\n            elif self.vae_type == \"vanilla\":\n                model_loss = K.mean(r_loss + kl_loss())\n            return model_loss\n\n        return(seq2seq_loss)\n    \n    def L_KL(self, *args, **kwargs):\n        '''KL loss function\n        '''\n        kl_loss = 1 + self.z_log_sigma - K.square(self.z_mu) - K.exp(self.z_log_sigma)\n        kl_loss = -0.5 * K.sum(kl_loss, axis=-1)\n        return(kl_loss/self.reg)\n    \n    def L_KL_D(self, *args, **kwargs):\n        '''KL D loss function\n        '''\n        # expectation of mu (mean of distributions)\n        exp_mu = tf.reduce_mean(self.z_mu, axis=0)\n        # expectation of mu mu.tranpose\n        mu_expand1 = tf.expand_dims(self.z_mu, 1)\n        mu_expand2 = tf.expand_dims(self.z_mu, 2)\n        exp_mu_mu_t = tf.reduce_mean(mu_expand1 * mu_expand2, axis=0)\n        # covariance of model mean\n        cov = exp_mu_mu_t - tf.expand_dims(exp_mu, 0) * tf.expand_dims(exp_mu, 1)\n        diag_part = tf.diag_part(cov)\n        off_diag_part = cov - tf.diag(diag_part)\n        regulariser_od = tf.reduce_sum(off_diag_part**2)\n        regulariser_d = tf.reduce_sum((diag_part - 1)**2)\n        ## overall loss\n        dip_vae_regulariser = regulariser_d + regulariser_od\n        return(dip_vae_regulariser/self.reg)\n    \n    def L_KL_Dii(self, *args, **kwargs):\n        '''KL Dii loss function\n        '''\n        ## E(Cov(...))\n        sigma = tf.matrix_diag(tf.exp(self.z_log_sigma))\n        exp_cov = tf.reduce_mean(sigma, axis=0)\n        ## Cov(E(...))\n        # expectation of mu (mean of distributions)\n        exp_mu = tf.reduce_mean(self.z_mu, axis=0)\n        # expectation of mu mu.tranpose\n        mu_expand1 = tf.expand_dims(self.z_mu, 1)\n        mu_expand2 = tf.expand_dims(self.z_mu, 2)\n        exp_mu_mu_t = tf.reduce_mean( mu_expand1 * mu_expand2, axis=0)\n        # covariance of model mean\n        cov_exp = exp_mu_mu_t - tf.expand_dims(exp_mu, 0) * tf.expand_dims(exp_mu, 1)\n        cov_z = cov_exp + exp_cov\n\n        diag_part = tf.diag_part(cov_z)\n        off_diag_part = cov_z - tf.diag(diag_part)\n\n        regulariser_od = tf.reduce_sum(off_diag_part**2)\n        regulariser_d = tf.reduce_sum((diag_part - 1)**2)\n        dip_vae_regulariser = regulariser_d + regulariser_od\n        return(dip_vae_regulariser/self.reg)\n\n    def L_XENT(self, x, z_decoded):\n        '''cross entropy loss\n        '''\n        x = K.flatten(x)\n        z_decoded = K.flatten(z_decoded)\n        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n        return(xent_loss)\n    \n    def L_MSE(self, x, z_decoded):\n        '''mean square error loss\n        '''\n        x = K.flatten(x)\n        z_decoded = K.flatten(z_decoded)\n        mse_loss = keras.metrics.mse(x, z_decoded)\n        return(mse_loss)\n    \n    def sampling(self, z_params):\n        '''Gets a list of [mu, sigma] and returns a random tensor \n        from the corresponding normal distribution \n        '''\n        mu, sigma = z_params\n        epsilon = K.random_normal(shape=(K.shape(mu)[0], latent_dim), mean=0.0, stddev=1.0)\n        return(mu + K.exp(sigma) * epsilon)\n        \n    def build_model(self):\n        '''Build the model\n        '''\n        ## Encoder \n        input_img = keras.Input(shape=img_shape)\n        x = layers.Conv2D(filters*1, 3,padding='same', activation='relu')(input_img)\n        x = layers.Conv2D(filters*1, 3,padding='same', activation='relu',strides=(2, 2))(x)\n        x = layers.Conv2D(filters*2, 3,padding='same', activation='relu')(x)\n        x = layers.Conv2D(filters*2, 3,padding='same', activation='relu',strides=(2, 2))(x)\n        x = layers.Conv2D(filters*4, 3,padding='same', activation='relu')(x)\n        x = layers.Conv2D(filters*4, 3,padding='same', activation='relu',strides=(2, 2))(x)\n        x = layers.Conv2D(filters*8, 3,padding='same', activation='relu')(x)\n        # need to know the shape of the network here for the decoder\n        shape_before_flattening = K.int_shape(x)\n        x = layers.Flatten()(x)\n        # dense layer\n        x = layers.Dense(32, activation='relu')(x)\n        # sampling layer \n        self.z_mu = layers.Dense(latent_dim)(x)\n        self.z_log_sigma = layers.Dense(latent_dim)(x)\n        # encoder model statement\n        self.encoder = Model(input_img, self.z_mu)\n    \n        ## Decoder \n        z = layers.Lambda(self.sampling)([self.z_mu, self.z_log_sigma])\n        decoder_input = layers.Input(K.int_shape(z)[1:])\n        # Expand to img_dim**2 total pixels\n        x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)\n        # reshape\n        x = layers.Reshape(shape_before_flattening[1:])(x)\n        # use Conv2DTranspose to reverse the conv layers from the encoder\n        x = layers.Conv2DTranspose(filters*1, 3,padding='same',activation='relu',strides=(2, 2))(x)\n        x = layers.Conv2DTranspose(filters*2, 3,padding='same',activation='relu',strides=(2, 2))(x)\n        x = layers.Conv2DTranspose(filters*4, 3,padding='same',activation='relu',strides=(2, 2))(x)\n        # Output layer\n        x = layers.Conv2D(1, 3,padding='same', activation='sigmoid')(x)\n        # decoder model statement\n        self.decoder = Model(decoder_input, x)\n\n        ##VAE\n        z_decoded = self.decoder(z)\n        # VAE model statement\n        model_o = Model(input_img, z_decoded)\n        \n        return model_o\n    \n    def compile(self):\n        '''Compiles the Keras model. Includes metrics to differentiate between the two main loss terms\n        '''\n        metrics = [self.L_KL]\n        \n        if vae_type == \"d\":\n            metrics.append(self.L_KL_D)\n        elif vae_type == \"dii\":\n            metrics.append(self.L_KL_Dii)\n        \n        if loss_type == \"xent\":\n            metrics.append(self.L_XENT)\n        elif loss_type == \"mse\":\n            metrics.append(self.L_MSE)\n            \n        self.model.compile(optimizer=self.optimizer, loss=self.loss_func, metrics=metrics)\n        print(\"beta = \", self.beta)\n\n        print('Model Compiled!')\n        \n# class KLWeightScheduler(Callback):\n#     \"\"\"KL weight scheduler.\n\n#     # Arguments\n#         kl_weight: The tensor withholding the current KL weight term\n#         schedule: a function that takes a batch index as input\n#             (integer, indexed from 0) and returns a new learning rate as output (float).\n#         verbose: int. 0: quiet, 1: update messages.\n#     \"\"\"\n\n#     def __init__(self, kl_weight, schedule, verbose=0):\n#         super(KLWeightScheduler, self).__init__()\n#         self.schedule = schedule\n#         self.verbose = verbose\n#         self.kl_weight = kl_weight\n#         self.count = 0  # Global batch index (the regular batch argument refers to the batch index within the epoch)\n\n#     def on_batch_begin(self, batch, logs=None):\n\n#         new_kl_weight = self.schedule(self.count)\n#         if not isinstance(new_kl_weight, (float, np.float32, np.float64)):\n#             raise ValueError('The output of the \"schedule\" function '\n#                              'should be float.')\n#         # Set new value\n#         K.set_value(self.kl_weight, new_kl_weight)\n#         if self.verbose > 0 and self.count % 20 == 0:\n#             print('\\nBatch %05d: KLWeightScheduler setting KL weight '\n#                   ' to %s.' % (self.count + 1, new_kl_weight))\n#         self.count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set key parameters\n\n# image dimension per single axis (images are square)\nimg_dim = 128\nimg_shape = (img_dim, img_dim, 1)   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#open data files for training and validation\nraw_x, df, num_images = openImgFile(\n    \"../input/vae09btvdds/vaetest09\", \n    \"index08.df\", \n    \"../../BTVDD_images/VAEtest09\", \n    1, img_dim, 10, 1000, hack=False)\n\n#open data files for calibration\ncalraw_x, caldf, calnum_images = openImgFile(\n    \"../input/cal01btvdd/cal01\", \n    \"CALindex01.df\", \n    \"../../BTVDD_images/CAL01\",\n    1, img_dim, 10, 20, hack = False)\n\n# raw_x, df, num_images = openImgFile(\n#     \"../goddard/Desktop/VAEtest09local\", \n#     \"index08.df\", \n#     \"../../BTVDD_images/VAEtest09\", \n#     10, img_dim, 10, 1000, hack=False)\n\n# #open data files for calibration\n# calraw_x, caldf, calnum_images = openImgFile(\n#     \"../goddard/Desktop/CAL01\", \n#     \"CALindex01.df\", \n#     \"../../BTVDD_images/CAL01\",\n#     1, img_dim, 10, 20, hack = False)\n\npreds = ['numBatches','nMKBH','nMKBV']\n\nnum_predictors, x_train, x_test, y_train, y_test = makeTrainValdata(raw_x, df, preds, img_dim, 0.1)\nx_cal = calraw_x.reshape((calraw_x.shape[0], img_dim, img_dim, 1))\ny_cal = np.array(caldf[preds].values)\nprint(x_train.shape,y_train.shape)\nprint(x_cal.shape,y_cal.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile VAE\ntry:\n    K.clear_session()\nexcept:\n    pass    \n\n# Number of latent dimension parameters\nlatent_dim = 10\n# Number of filters in encoder/decoder CNNs\nfilters = 32\n\n# alpha/beta/gamma/capacity parameters \nalpha = 750\nbeta = 15\ngamma = 10 # not needed yet!\ncapacity = 0 # not needed yet!\nlr = 0.0005\n\n# capacity callback\ncapacity_cb = CapacityIncrease(max_capacity=50, max_epochs=10)\n\n#vae regularisation\nvae_type=\"dii\"\n\n#reconstruction loss type\nloss_type = \"xent\"\n\n# compile vae\nvae  = vaeModel(alpha, beta, gamma, lr, capacity, img_shape, latent_dim, filters, vae_type, loss_type)\nvae.compile()\nmodel = vae.model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train VAE\nbatch_size = 32\nhist = model.fit(x=x_train, y=x_train,\n        shuffle=True,\n        epochs=100,\n        batch_size=batch_size,\n        callbacks=[capacity_cb],\n        validation_data=(x_test, x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Infer from train and test data\nz_train = vae.encoder.predict(x_train, batch_size=batch_size)\nz_test = vae.encoder.predict(x_test, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train c and z predictors\nbatch_size = 64\nsteps_per_epoch = max(1,len(x_train) // batch_size)\nvalidation_steps = max(1,len(x_test) // batch_size)\nprint(validation_steps)\noptmiser = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=0.00001, decay=0.0000001)\n\ncpredictor = create_predictor(latent_dim, num_predictors)\n#zpredictor = create_predictor(num_predictors, latent_dim)\n\ncpredictor.compile(loss='mse', optimizer=optmiser, metrics=['mse'])\n#zpredictor.compile(loss='mse', optimizer=optmiser, metrics=['mse'])\n\nprint(z_test.shape,y_test.shape)\nchist = cpredictor.fit(x=z_train, y=y_train,\n        epochs=40,\n        shuffle = True,\n        steps_per_epoch = steps_per_epoch,\n        validation_steps = validation_steps,\n        validation_data=(z_test, y_test))\n\n# zhist = zpredictor.fit(x=y_train, y=z_train,\n#         epochs=40,\n#         shuffle = True,\n#         steps_per_epoch = steps_per_epoch,\n#         validation_steps = validation_steps,\n#         validation_data=(y_test, z_test))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fn = \"BTVDD_09_02.h5\"\n# vae.save(\"vae_z\" + str(latent_dim) + fn)\n# decoder.save(\"decoder_z\" + str(latent_dim) + fn)\n# encoder.save(\"encoder_z\" + str(latent_dim) + fn)\n# #zpredictor.save(\"zpredictor_z\" + str(latent_dim) + fn)\n# cpredictor.save(\"cpredictor_z\" + str(latent_dim) + fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# fn = \"BTVDD_09_02.h5\"\n# vae = load_model(\"vae_z\" + str(latent_dim) + fn,\n#                  custom_objects={'CustomVariationalLayer': CustomVariationalLayer,\n#                                  'latent_dim': latent_dim}, \n#                  compile=False)\n# #vae = load_model(\"vae_\" + fn, custom_objects={'CustomVariationalLayer': CustomVariationalLayer,'latent_dim': latent_dim})\n# decoder = load_model(\"decoder_z\" + str(latent_dim) + fn,\n#                  custom_objects={'CustomVariationalLayer': CustomVariationalLayer,\n#                                  'latent_dim': latent_dim}, \n#                  compile=False)\n# encoder = load_model(\"encoder_z\" + str(latent_dim) + fn,\n#                  custom_objects={'CustomVariationalLayer': CustomVariationalLayer,\n#                                  'latent_dim': latent_dim}, \n#                  compile=False)\n# zpredictor = load_model(\"zpredictor_z\" + str(latent_dim) + fn)\n# cpredictor = load_model(\"cpredictor_z\" + str(latent_dim) + fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_out = cpredictor.predict(z_train, steps = 1)\n\nr2 = np.zeros((3))\n\nplt.figure(figsize=(12, 3.5))\nfor i in range(num_predictors):\n    plt.subplot(1,num_predictors, i+1)\n    r2[i] = rsq(y_train[:,i], y_out[:,i])\n    plt.scatter(y_train[:,i], y_out[:,i], c=y_train[:,0],\n                alpha=.4, cmap='viridis')\n    plt.xlabel('Ground truth')\n    plt.ylabel('Predictor ' + str(i+1))\n    plt.title(\"P\" + str(i+1) + \": $R^2$ = \" + str(round(r2[i],4)))\n    plt.grid()\n    plt.colorbar()\nplt.show()\n\nprint(latent_dim,r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make semantic test across z space using x_cal, y_cal, interpolating linearly between z\nsteps = 11\nx_dec = []\nc_dec = []    \n\nfor h in range(1,calnum_images):\n    samples = [0,h] #index for sample image\n    myz = []\n    for i in samples:\n        z = vae.encoder.predict(x_cal[i].reshape((1,img_dim,img_dim,1)), batch_size=1)\n        myz.append(z)\n\n    for k in range(steps+1):\n        mynewz = k/steps*myz[0]+(1-k/steps)*myz[1]\n        if k == 0:\n            x_dec.append(x_cal[i].reshape((1,img_dim,img_dim,1)))\n        elif k == steps:\n            x_dec.append(x_cal[0].reshape((1,img_dim,img_dim,1)))\n        else:\n            x_dec.append(vae.decoder.predict(mynewz))\n            #c_dec.append(cpredictor.predict(mynewz))\n\nx_dec = np.array(x_dec)\nx_dec = x_dec.reshape(calnum_images-1,steps+1,img_dim, img_dim)\n\nfig, ax = plt.subplots(figsize = (16,18))\nax.imshow(np.block(list(map(list, x_dec))), \n    cmap='gray', interpolation='none', \n    extent=([0,steps+1,calnum_images-1,0]))\nax.set_aspect(1)\nplt.show()\nc_dec = np.array(c_dec)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #make semantic test across z space using x_cal, y_cal, moving orthoganally along z, for samples 1-4, for len(modes) z directions\n# steps = 11\n# x_dec = []\n# c_dec = []    \n# zr = 0.2\n# modes = [0,6,8]\n\n# for h in range(1,5):\n#     for j in modes:\n#         z = vae.encoder.predict(x_cal[h].reshape((1,img_dim,img_dim,1)), batch_size=1)\n#         zt = z[0][j]\n#         for k in range(steps+1):\n#             if k == (steps - 1) / 2:\n#                 x_dec.append(x_cal[h].reshape((1,img_dim,img_dim,1)))\n#             else:\n#                 z[0][j] = zt + zr * (k - (steps - 1) / 2)\n#                 x_dec.append(vae.decoder.predict(z))\n#                 c_dec.append(cpredictor.predict(z))\n                \n# x_dec = np.array(x_dec)\n# x_dec = x_dec.reshape(4*len(modes),steps+1,img_dim, img_dim)\n\n# fig, ax = plt.subplots(figsize = (16,6*len(modes)))\n# ax.imshow(np.block(list(map(list, x_dec))), \n#     cmap='gray', interpolation='none', \n#     extent=([0,steps+1,calnum_images-1,0]))\n# ax.set_aspect(1)\n# plt.show()\n# c_dec = np.array(c_dec)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = z_train\n\n# Full SVD: results that the matrices are not full\n# s are the singular values => They need to be squared to get the eigenvalues\n\nu, lam, v = np.linalg.svd(data)\n\nnumber_eigval = range(1, len(lam) + 1)\n# \nplt.figure()\nplt.contourf(data)\n\n# %%\nM = np.dot(u[:, :len(lam)] * lam, v)\n\nplt.figure()\nplt.contourf(M)\n\n# Check if relative difference smaller than 1e-3\nnp.allclose(data, M, rtol=1e-3)\n# %%\n\nu_r, lam_r, v_red = np.linalg.svd(data, full_matrices=False)\n\nM_r = np.dot(u_r * lam_r, v_red)\n\nplt.figure()\nplt.contourf(M_r)\nnp.allclose(data, M_r, rtol=1e-3)\n# %%\nM = np.zeros(data.shape)\n\nfor i in range(v.shape[1]):\n    ui, vi = u[:, i], v[:, i]\n    ui = ui.reshape(u.shape[0], 1)\n    vi = vi.reshape(1, v.shape[0])\n    M = M + (lam[i] * np.dot(ui, vi))\nplt.figure()\nplt.contourf(M)\n# %%\nplt.figure()\nplt.plot(number_eigval, lam**2/lam[0]**2, 'o-')\nplt.grid()\nplt.xlabel(\"z index\")\nplt.ylabel(\"Eigenvalue\")\nplt.title(\"Eigenvalues of latent space matrix\")\nplt.show()\n\n\ndef diagonaliseZ(data_z, check_tol=None, full_matrices=False):\n    \"\"\"\"\n    Take a Z space matrix (m x n), with m input size and n Z-space size and returns\n    U, lambda and V.T matrices of SVD decomposition. Can also check how close it is to the\n    orginal matrix using the 'check_tol' parameter\n    @param data_z: Z matrix\n    @param check_tol: relative of the difference to check\n    @param full_matrices: return full matrices, default False\n    :return U matrix (m x n) (or (m x m) if full_matrices=True), vector of singular values and V matrix (n x n)\n    \"\"\"\n    u_r, lam_r, v_r = np.linalg.svd(data_z, full_matrices=full_matrices)\n\n    M_r = np.dot(u_r * lam_r, v_r)\n\n    if not check_tol == None:\n        print('M - Z = 0 (+/-%.1e x Z): '%check_tol, np.allclose(data, M_r, rtol=1e-3))\n\n    return u_r, lam_r, v_r\n\n\nu, lam, v = diagonaliseZ(data, check_tol=1e-3)\n\ndef changeOrth(data_z, index, n_val=[], n_val_delta=[], n_val_r=[], **kwargs):\n    \"\"\"\"\n    Change the singular value (SV) 'index' by a given quantity. This can also be relative or a delta. \n    Order is priority. \n    @param data_z: Z matrix\n    @param index: index of the SV to change\n    @param n_val: value that will replace the SV\n    @param n_val_delta: delta to change for the given SV\n    @param n_val_r: relative change of the given SV\n    :return Z matrix with the demanded change\n    \"\"\"\n    u_t, l_t, v_t = diagonaliseZ(data_z, **kwargs)\n\n    if n_val != []:\n        l_t[index] = n_val\n    elif n_val_delta != []:\n        l_t[index] = l_t[index] + n_val_delta\n    elif n_val_r != []:\n        l_t[index] = l_t[index] + l_t[index] * n_val_delta\n\n    return np.dot(u_t * l_t, v_t)\n\ndef changeZ(data_z, index, n_val=[], n_val_delta=[], n_val_r=[], **kwargs):\n    \"\"\"\"\n    Change the singular value (SV) 'index' by a given quantity. This can also be relative or a delta. \n    Order is priority. \n    @param data_z: Z matrix\n    @param index: index of the SV to change\n    @param n_val: value that will replace the SV\n    @param n_val_delta: delta to change for the given SV\n    @param n_val_r: relative change of the given SV\n    :return Z matrix with the demanded change\n    \"\"\"\n    data_z_temp = np.copy(data_z)\n    for i in range(data_z_temp.shape[0]):\n        if n_val != []:\n            data_z_temp[i, index[0]:index[1]] = n_val\n        elif n_val_delta != []:\n            data_z_temp[i, index[0]:index[1]] = data_z_temp[i, index[0]:index[1]] + n_val_delta\n        elif n_val_r != []:\n            data_z_temp[i, index[0]:index[1]] = data_z_temp[i, index[0]:index[1]] + data_z_temp[i, index[0]:index[1]] * n_val_delta\n\n    return data_z_temp\n\nM = changeOrth(data, [0, 1], n_val_delta=[1, 10])\n\nM_red = np.dot(u[:, :3] * lam[:3], v[:3, :3])\n\nplt.figure()\nplt.plot(data[:, 0], 'o')\nplt.plot(M_red[:, 0])\n\nz_n = changeZ(data, (0, 2), n_val_delta=[1, 2])\nprint(z_n[0, 0:2] - data[0, 0:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## \n\nplt.figure(figsize=(6, 6))\nplt.scatter(z_test[:, 0], z_test[:, 3], c=y_test[:, 1],alpha=.4, cmap='viridis')\n#plt.scatter(z_train[:, 0], z_train[:, 1])\nplt.xlabel('Z[0]')\nplt.ylabel('Z[1]')\nplt.colorbar()\nplt.grid()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Plot images generated from orthogonalised z space\nmydata = vae.encoder.predict(x_test, batch_size=batch_size)\ntest_img = 7\nn = 11\nmaxbase = 3\nnormp = (20,4,6)\n\nfor j in range(maxbase+1):\n    bases = [j]\n    x_decoded = []\n    c_decoded = []\n    for i in range(n):\n        M_new = changeOrth(mydata, bases, # v in image    h in image\n                           n_val_delta=[(-i-(n-1)/2)*2])[test_img:test_img+1, :]\n        x_decoded.append(vae.decoder.predict(M_new))\n        c_decoded.append(cpredictor.predict(M_new))\n    x_decoded = np.array(x_decoded)\n    x_decoded = x_decoded.reshape(1,n,img_dim, img_dim)\n\n    fig, ax = plt.subplots(figsize = (15,4))\n    ax.imshow(np.block(list(map(list, x_decoded))), \n        cmap='gray', interpolation='none', \n        extent=([-(n-1)//2,(n-1)//2,-0.5,0.5]))\n    ax.set_aspect(1)\n    plt.xlabel('z_orthogonal ' + str(j))\n    plt.show()\n    c_decoded = np.array(c_decoded)\n    \n    plt.figure(figsize = (16,2))\n    for k in range(num_predictors):\n        plt.plot(c_decoded[:,0][:,k]/normp[k],'-',label=preds[k])\n    plt.ylim(0,1.1)\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Plot images generated from orthogonalised z space\n#z_test = encoder.predict(x_test, batch_size=batch_size)\nmydata = vae.encoder.predict(x_test, batch_size=batch_size)\n#mydata = data\ntest_img = 1\nn = 9\nbases1 = [0,1]\n\nx_decoded = []\nc_decoded = []\nfor i in range(n):\n    for j in range(n):\n        M_new = changeOrth(mydata, bases1, # v in image    h in image\n                           n_val_delta=[(i-(n-1)/2)*4,(j-(n-1)/2)*4])[test_img:test_img+1, :]\n        x_decoded.append(vae.decoder.predict(M_new))\n        c_decoded.append(cpredictor.predict(vae.encoder.predict(vae.decoder.predict(M_new))))\nx_decoded = np.array(x_decoded)\nx_decoded = x_decoded.reshape(n,n, img_dim, img_dim)\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.imshow(np.block(list(map(list, x_decoded))), \ncmap='gray', interpolation='none', \nextent=[-5,5,-5,5])\nax.set_aspect(1)\nplt.xlabel('Z_test_0')\nplt.ylabel('Z_test_1')\nplt.show()\nc_decoded = np.array(c_decoded)\n\nplt.figure()\nfor i in range(n):\n    if i == 0:\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,0],'ro-',label=preds[0])\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,1],'gx-',label=preds[1])\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,2],'b+-',label=preds[2])\n    else:\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,0],'ro-')\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,1],'gx-')\n        plt.plot(c_decoded[i*n:((i+1)*n),0][:,2],'b+-')        \nplt.legend()\nplt.grid()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nPlot images generated from regular z space\n\"\"\"\nbases = [0,2]\nmydata = vae.encoder.predict(x_test, batch_size=batch_size)\nd = 0.3\nun_grid = np.dstack(np.meshgrid(np.linspace(d, 1-d, n)))\n#un_grid = np.dstack(np.meshgrid(np.linspace(d, 1-d, n),\n#                               np.linspace(d, 1-d, n)))\nzn_grid = norm.ppf(un_grid)[0]\n#zn_grid = un_grid[0]\n\nN_new = mydata[test_img:test_img+1, :]\nprint(N_new)\n\nN0 = [N_new[0,bases[0]],N_new[0,bases[1]]]\nir = 10\njr = 10\n\nxn_decoded = []\ncn_decoded = []\n\nfor i in range(n):\n    N_new[0,bases[0]] = N0[0]+zn_grid[i]\n    for j in range(n):\n        N_new[0][bases[1]] = N0[1]+zn_grid[j]\n        #print(N_new[0],bases[0],N_new[0],bases[1])\n        xn_decoded.append(vae.decoder.predict(N_new))\n        cn_decoded.append(cpredictor.predict(vae.encoder.predict(vae.decoder.predict(N_new))))\nxn_decoded = np.array(xn_decoded)\nxn_decoded = xn_decoded.reshape(n,n, img_dim, img_dim)\n#print(N_new)\n\nfig, ax = plt.subplots(figsize=(10, 10))\nax.imshow(np.block(list(map(list, xn_decoded))), \ncmap='gray', interpolation='none', \nextent=[-5,5,-5,5])\nax.set_aspect(1)\nplt.xlabel('Z_test_0')\nplt.ylabel('Z_test_1')\n\ncn_decoded = np.array(cn_decoded)\nprint(cn_decoded.shape)\n\nplt.figure()\nfor i in range(n):\n    if i == 0:\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,0],'ro-',label=preds[0])\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,1],'gx-',label=preds[1])\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,2],'b+-',label=preds[2])\n    else:\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,0],'ro-')\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,1],'gx-')\n        plt.plot(cn_decoded[i*n:((i+1)*n),0][:,2],'b+-')        \nplt.legend()\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}